# Testing Standards

---
description: Testing conventions, mocking patterns, and coverage expectations
globs: ["**/test_*.py", "**/*.test.ts", "**/*.test.tsx", "**/tests/**"]
alwaysApply: false
---

## Testing Philosophy

Tests are documentation that runs. They prove the code works and explain how it should be used.

**Principle**: Test behavior, not implementation. Tests should survive refactoring.

## Test Pyramid

```
        /\
       /  \      E2E Tests (few)
      /----\     - Full user flows
     /      \    - Slow, expensive
    /--------\   
   /          \  Integration Tests (some)
  /------------\ - Component interactions
 /              \- Database, API calls
/----------------\
      Unit Tests (many)
      - Single function/class
      - Fast, isolated
```

## Python Testing (pytest)

### Directory Structure

```
backend/
  tests/
    __init__.py
    conftest.py           # Shared fixtures
    unit/
      __init__.py
      test_deck.py
      test_spreads.py
      test_prompts.py
    integration/
      __init__.py
      test_reading_service.py
      test_llm_backend.py
    fixtures/
      cards.json
      readings.json
```

### Naming Conventions

```python
# File: test_<module>.py
# Function: test_<what>_<condition>_<expected>

def test_draw_cards_returns_requested_count():
    """Draw 3 cards returns exactly 3 cards."""
    ...

def test_draw_cards_with_empty_deck_raises_error():
    """Drawing from empty deck raises DeckExhaustedError."""
    ...

def test_reading_creation_deducts_credits():
    """Creating a reading deducts credits from user."""
    ...
```

### Fixtures

```python
# conftest.py

import pytest
from app.core.tarot.deck import Deck, Card

@pytest.fixture
def deck() -> Deck:
    """Fresh shuffled deck for testing."""
    return Deck.create_standard()

@pytest.fixture
def sample_cards() -> list[Card]:
    """Predictable set of cards for testing."""
    return [
        Card(id="major_0", name="The Fool", is_major=True),
        Card(id="major_1", name="The Magician", is_major=True),
        Card(id="major_2", name="The High Priestess", is_major=True),
    ]

@pytest.fixture
def mock_llm_response():
    """Mock LLM response for testing."""
    return "This reading suggests a time of new beginnings..."
```

### Async Testing

```python
import pytest

@pytest.mark.asyncio
async def test_create_reading_success(mock_llm, mock_db):
    """Reading creation succeeds with valid inputs."""
    service = ReadingService(llm=mock_llm, db=mock_db)
    
    reading = await service.create(
        question="What should I focus on?",
        spread_type=SpreadType.THREE_CARD,
        user_id="user_123",
    )
    
    assert reading.id is not None
    assert len(reading.cards) == 3
    assert reading.interpretation is not None
```

### Mocking LLM Responses

```python
import pytest
from unittest.mock import AsyncMock, patch

@pytest.fixture
def mock_llm():
    """Mock LLM backend that returns predictable responses."""
    llm = AsyncMock()
    llm.generate.return_value = "The cards reveal a journey of transformation..."
    return llm

async def test_interpretation_uses_llm(mock_llm, sample_cards):
    """Interpretation calls LLM with formatted prompt."""
    service = ReadingService(llm=mock_llm)
    
    await service.interpret(sample_cards, "What lies ahead?")
    
    mock_llm.generate.assert_called_once()
    call_args = mock_llm.generate.call_args
    assert "The Fool" in call_args.kwargs["prompt"]
    assert "What lies ahead?" in call_args.kwargs["prompt"]
```

### Testing Exceptions

```python
import pytest
from app.core.exceptions import InsufficientCreditsError

async def test_reading_without_credits_raises():
    """Reading creation fails when user has no credits."""
    user = create_user(credits=0)
    service = ReadingService(...)
    
    with pytest.raises(InsufficientCreditsError) as exc_info:
        await service.create(user_id=user.id, ...)
    
    assert exc_info.value.code == "INSUFFICIENT_CREDITS"
    assert "0 available" in str(exc_info.value)
```

### Parametrized Tests

```python
import pytest
from app.core.tarot.spreads import SpreadType

@pytest.mark.parametrize("spread_type,expected_count", [
    (SpreadType.SINGLE, 1),
    (SpreadType.THREE_CARD, 3),
    (SpreadType.CELTIC_CROSS, 10),
])
def test_spread_card_count(spread_type, expected_count):
    """Each spread type draws correct number of cards."""
    spread = create_spread(spread_type)
    assert len(spread.positions) == expected_count
```

## TypeScript Testing (Vitest)

### Directory Structure

```
frontend/
  src/
    test/
      setup.ts               # Test environment setup
      utils.tsx              # Custom render with providers
      mocks/
        handlers.ts          # MSW request handlers
        server.ts            # MSW server instance
    components/
      ui/
        button.test.tsx      # Button component tests
        card.test.tsx        # Card component tests
        input.test.tsx       # Input component tests
    lib/
      utils.test.ts          # Utility function tests
      api.test.ts            # API client tests
  __tests__/
    integration/             # Component interaction tests
      .gitkeep
      README.md
    e2e/                     # End-to-end tests (Playwright)
      .gitkeep
      README.md
```

### Component Testing

```typescript
// button.test.tsx
import { describe, it, expect, vi } from 'vitest';
import { render, screen } from '@/test/utils';
import { Button } from './button';

describe('Button', () => {
  it('renders with children text', () => {
    render(<Button>Click me</Button>);
    expect(screen.getByRole('button', { name: 'Click me' })).toBeInTheDocument();
  });

  it('applies correct variant classes', () => {
    render(<Button variant="mystical">Mystical</Button>);
    const button = screen.getByRole('button');
    expect(button.className).toContain('from-void');
    expect(button.className).toContain('to-midnight');
  });

  it('handles click events', () => {
    const handleClick = vi.fn();
    const { container } = render(
      <Button onClick={handleClick}>Click</Button>
    );
    const button = container.querySelector('button') as HTMLButtonElement;
    button?.click();
    expect(handleClick).toHaveBeenCalled();
  });

  it('renders as child component when asChild is true', () => {
    render(
      <Button asChild>
        <a href="/test">Link Button</a>
      </Button>
    );
    expect(screen.getByRole('link')).toHaveAttribute('href', '/test');
  });
});
```

### API Client Testing

```typescript
// api.test.ts
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { APIClient } from './api';

describe('APIClient', () => {
  let client: APIClient;

  beforeEach(() => {
    client = new APIClient('http://test-api');
    vi.resetAllMocks();
  });

  describe('GET requests', () => {
    it('makes GET requests with correct headers', async () => {
      global.fetch = vi.fn().mockResolvedValue({
        ok: true,
        json: () => Promise.resolve({ data: 'test' }),
      });

      await client.get<{ data: string }>('/endpoint');

      expect(fetch).toHaveBeenCalledWith('http://test-api/endpoint', {
        method: 'GET',
        headers: { 'Content-Type': 'application/json' },
      });
    });

    it('throws on non-ok response', async () => {
      global.fetch = vi.fn().mockResolvedValue({
        ok: false,
        status: 404,
        json: () => Promise.resolve({ detail: 'Not found' }),
      });

      await expect(client.get('/missing')).rejects.toThrow('Not found');
    });
  });

  describe('POST requests', () => {
    it('sends data with correct method and headers', async () => {
      const postData = { question: 'What should I do?' };
      global.fetch = vi.fn().mockResolvedValue({
        ok: true,
        json: () => Promise.resolve({ id: '123' }),
      });

      await client.post('/reading', postData);

      expect(fetch).toHaveBeenCalledWith('http://test-api/reading', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(postData),
      });
    });
  });
});
```

### Integration Tests

```typescript
// __tests__/integration/reading-flow.test.tsx
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { render, screen, fireEvent, waitFor } from '@/test/utils';
import { server } from '@/test/mocks/server';
import { http, HttpResponse } from 'msw';

const API_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';

describe('Reading Flow', () => {
  beforeAll(() => server.listen());
  afterAll(() => server.close());

  it('completes full reading flow', async () => {
    // Setup mock API response
    server.use(
      http.post(`${API_URL}/reading`, () => {
        return HttpResponse.json({
          id: '123',
          cards: [
            { id: 'card_0', name: 'The Fool', position: 'Past' },
          ],
          interpretation: 'A new beginning awaits...',
        });
      })
    );

    render(<ReadingPage />);

    // Enter question
    const input = screen.getByPlaceholderText(/question/i);
    fireEvent.change(input, { target: { value: 'What should I focus on?' } });

    // Submit
    fireEvent.click(screen.getByRole('button', { name: /draw/i }));

    // Wait for results
    await waitFor(() => {
      expect(screen.getByText('The Fool')).toBeInTheDocument();
      expect(screen.getByText(/new beginning/i)).toBeInTheDocument();
    });
  });
});
```

## Coverage Expectations

### Frontend Coverage Targets

| Area | Target | Current |
|------|--------|---------|
| Utilities | 100% | 100% |
| API Client | 100% | 100% |
| UI Components | 90% | 100% (Button, Card, Input) |
| Overall | 80% | 60.21% |

### Backend Coverage Targets

| Area | Target |
|------|--------|
| Core business logic | 90% |
| API endpoints | 80% |
| Services | 85% |
| Tarot logic | 90% |

### Running Coverage

```bash
# Python
pytest --cov=app --cov-report=html

# TypeScript
npm run test:coverage
```

### What to Test

**Always test:**
- Business logic (reading creation, credit deduction)
- Validation (input sanitization, error cases)
- Edge cases (empty inputs, max limits)
- Error handling (exceptions, API failures)

**Don't test:**
- Third-party libraries
- Implementation details that might change
- Trivial getters/setters
- Framework internals

## Test-Driven Development

### Red-Green-Refactor Cycle

```python
# 1. RED: Write failing test
def test_celtic_cross_has_ten_positions():
    spread = CelticCrossSpread()
    assert len(spread.positions) == 10  # Fails - not implemented

# 2. GREEN: Make it pass (minimal implementation)
class CelticCrossSpread:
    positions = ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"]

# 3. REFACTOR: Improve while keeping tests green
class CelticCrossSpread:
    positions = [
        "Significator", "Crossing", "Foundation", "Recent Past",
        "Crown", "Near Future", "Self", "Environment", 
        "Hopes/Fears", "Outcome"
    ]
```

## Pre-Commit Test Requirements

Before committing (automatic via Husky hooks):

```bash
# Pre-commit hook runs:
npx lint-staged           # ESLint, Prettier, type-check on staged files

# Pre-push hook runs:
npm run type-check && npm test -- --run    # Full test suite must pass

# Manual verification:
npm run type-check        # Type checking
npm run lint              # Linting
npm test -- --run         # All tests
npm run test:coverage     # Coverage report
```

## CI Test Configuration

```yaml
# .github/workflows/test.yml
name: Tests

on: [push, pull_request]

jobs:
  backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - run: pip install -e ".[dev]"
      - run: pytest --cov=app --cov-fail-under=80

  frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      - run: npm ci
      - run: npm run type-check
      - run: npm run lint
      - run: npm test -- --run
      - run: npm run test:coverage

  e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      - run: npm ci
      - run: npx playwright install
      - run: npm run test:e2e
```

